# Python CircleCI 2.1 configuration file
#
# Check https://circleci.com/docs/2.0/language-python/ for more details
#
version: 2.1
orbs:
  slack: circleci/slack@3.4.2
commands:
  update-submodules:
    steps:
      - run:
          # `git submodule update --remote` checks out the submodule repo's
          # HEAD (as opposed to whatever commit is specified in the
          # submodule). We want to ensure we're always testing against
          # the most recent commit in our component-template repo.
          name: Update submodules
          command: |
            git submodule init
            git submodule update --remote

  pre-cache:
    steps:
      - run: &get_make_checksum
          name: Get 'make' checksum
          command: |
            echo 'export SUDO="sudo"' >> $BASH_ENV
            cp -f /usr/bin/make make.bin
            md5sum make.bin > ~/make.md5

      - run: &get_dot_checksum
          name: Get 'dot' checksum
          command: |
            if [ -f /usr/bin/dot ] ; then
              cp -f /usr/bin/dot dot.bin
              md5sum dot.bin > ~/dot.md5
            else
              touch dot.bin
              md5sum dot.bin > ~/dot.md5
              rm -f dot.bin
            fi

      - run: &create_python_cache_key
          # Combine hashes of the Python interpreter, Pipfile, and today's
          # date into a file whose checksum will key the Python virtualenv.
          #
          # This means that our virtualenv cache will expire each day. We do
          # this because we are not using a lockfile to pin dependencies -
          # instead, each time CircleCI rebuilds the virtualenv, it uses the
          # latest compatible version of each dependency (which mirrors what
          # happens when a user installs Streamlit locally). So we expire our
          # virtualenv cache daily to prevent it from getting far out of sync
          # with what a fresh Streamlit installation would look like.
          name: Create Python environment cache key
          command: |
            md5sum $(which python) > ~/python_cache_key.md5
            md5sum lib/Pipfile >> ~/python_cache_key.md5
            md5sum lib/test-requirements.txt >> ~/python_cache_key.md5
            date +%F >> ~/python_cache_key.md5

      - run: &create_yarn_cache_key
          name: Create Yarn cache key
          command: |
            md5sum frontend/yarn.lock > ~/yarn.lock.md5

  restore-from-cache:
    steps:
      - restore_cache: &restore_virtualenv
          name: Restore virtualenv from cache
          keys:
            - v13-python-venv-{{ checksum "~/python_cache_key.md5" }}

      - restore_cache: &restore_nvm
          name: Restore nvm and node_modules from cache
          keys:
            - v13-nvm_node_modules-{{ checksum "~/yarn.lock.md5" }}

      - restore_cache: &restore_make
          name: Restore make from cache
          keys:
            - v13_make.bin-{{ checksum "~/make.md5" }}

      - restore_cache: &restore_dot
          name: Restore dot from cache
          keys:
            - v13_dot.bin-{{ checksum "~/dot.md5" }}

  pre-make:
    steps:
      - run: &install_make
          name: Install make
          command: |
            if [ -s make.bin ] ; then
              echo "make.bin exists; not installing"
            else
              echo "/usr/bin/make doesn't exist; installing"
              apt-get update -y
              apt-get install -y make
              cp -f /usr/bin/make make.bin
            fi
            ${SUDO} cp -f make.bin /usr/bin/make

      - run: &install_dot
          name: Install dot
          command: |
            if [ -s dot.bin ] ; then
              echo "dot.bin exists and is non zero"
            else
              echo "/usr/bin/dot doesn't exist, installing"
              ${SUDO} apt-get update -y
              ${SUDO} apt-get install -y graphviz
              cp -f /usr/bin/dot dot.bin
            fi
            ${SUDO} cp -f dot.bin /usr/bin/dot

  make-init:
    steps:
      - run: &install_nodejs
          name: Install NVM, Node.js, and Yarn
          command: |
            if [ ! -d ~/.nvm ] ; then
              # install nodejs via nvm
              curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.35.2/install.sh | bash
              source "$HOME/.nvm/nvm.sh"
              nvm install --lts=dubnium
              # install yarn
              npm install -g yarn
            fi
            if [ ! -d frontend/node_modules ] ; then
              source "$HOME/.nvm/nvm.sh"
            fi
            make react-init scssvars
            echo 'export NVM_DIR="$HOME/.nvm"' >> $BASH_ENV
            echo 'source "$NVM_DIR/nvm.sh"' >> $BASH_ENV

      - run:
          name: Install pyodbc dependencies
          command: |
            ${SUDO} apt-get install -y unixodbc-dev

      - run:
          name: Install graphviz dependencies
          command: |
            ${SUDO} apt-get install -y libgvc6

      - run: &activate_virtualenv
          name: Create virtualenv
          command: |
            echo 'Checking for virtualenv'
            if [ ! -d venv ] ; then
              # The virtualenv was NOT restored from cache. Create a new one.
              python -m venv venv
              source venv/bin/activate
              pip install --upgrade pip
              make setup
              make pipenv-install
              # Looks like the pinned setuptools is not being respected
              # In the meantime, forcing a reinstall of setuptools to unblock
              # TODO: Cleanup as part of GH #1963
              pip install "setuptools<=49.6.0" --force-reinstall --no-cache-dir
              pip show setuptools
              deactivate
            else
              # The virtualenv WAS restored from cache. Don't create a new one.
              echo 'Virtualenv already exists, not creating'
            fi

            # Add 'activate venv' to $BASH_ENV. This means that our venv will be active
            # for the remainder of the job ($BASH_ENV is evaluated at each step).
            echo 'source venv/bin/activate' >> $BASH_ENV

      - run: &generate_protobufs
          name: Generate protobufs
          command: |
            # install protobuf v3
            ${SUDO} apt-get update -y
            ${SUDO} apt-get install -y gnupg
            echo "deb http://ppa.launchpad.net/maarten-fonville/protobuf/ubuntu trusty main" | ${SUDO} tee /etc/apt/sources.list.d/protobuf.list
            ${SUDO} apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 4DEA8909DC6A13A3
            ${SUDO} apt-get update -y
            ${SUDO} apt-get install -y protobuf-compiler

            # Generate protobufs
            make protobuf

workflows:
  circleci:
    jobs:
      - python-3-6: # Oldest supported Python minor version.
          filters:
            tags:
              only: /^([0-9]+\.){3}dev[0-9]+/ # 0.56.1.dev20201129
      - python-3-8: # Latest supported Python minor version.
          filters:
            tags:
              only: /^([0-9]+\.){3}dev[0-9]+/
      - cypress: # Non flaky Cypress tests
          requires:
            - python-3-8
          filters:
            tags:
              only: /^([0-9]+\.){3}dev[0-9]+/
      - pr-preview: # Make a preview branch for each PR
          context:
            - pr-preview
          filters:
            tags:
              only: /^([0-9]+\.){3}dev[0-9]+/
      - nightly-release:
          requires:
            - python-3-6
            - python-3-8
            - cypress
          filters:
            tags:
              only: /^([0-9]+\.){3}dev[0-9]+/
            branches:
              ignore: /.*/
      - cypress-flaky-approval:
          type: approval
          requires:
            - python-3-8
      - cypress: # Flaky Cypress tests
          name: cypress-flaky
          flaky: true
          requires:
            - cypress-flaky-approval

  create-nightly-tag:
    triggers:
      - schedule:
          # Run job at 10.30pm PST or 11.30pm PDT
          cron: "30 6 * * *"
          filters:
            branches:
              only:
                - develop
    jobs:
      - create-tag

jobs:
  python-3-8: &job-template
    docker:
      - image: circleci/python:3.8.1

    working_directory: ~/repo

    steps:
      - checkout:
          name: Checkout Streamlit code

      - update-submodules

      #################################################################
      # Pre Cache Steps
      #################################################################
      - pre-cache

      #################################################################
      # Restore from cache
      #################################################################
      - restore-from-cache

      #################################################################
      # Pre Make commands
      #################################################################
      - pre-make

      - save_cache:
          name: Save make to cache
          key: v13_make.bin-{{ checksum "~/make.md5" }}
          paths:
            - make.bin

      - save_cache:
          name: Save dot to cache
          key: v13_dot.bin-{{ checksum "~/dot.md5" }}
          paths:
            - dot.bin

      #################################################################
      # Run 'make init'
      #################################################################
      - make-init

      - run: &make_develop
          name: Run make develop
          command: |
            make develop

      #################################################################
      # Run linters
      #################################################################
      - run:
          name: Run linters
          command: |
            make jslint
            make pylint

      - store_test_results:
          path: frontend/test-reports
          when: always

      #################################################################
      # Run mypy. (Only executed in one job.)
      #################################################################
      - run:
          name: Run mypy
          command: |
            if [ "${CIRCLE_JOB}" != "python-3-8" ] ; then
              echo "Mypy is only run in python-3.8 job"
            else
              scripts/mypy --report
            fi

      - store_test_results:
          path: lib/test-reports
          when: always

      #################################################################
      # Run make pycoverage
      #################################################################
      - run:
          name: Run python tests
          command: |
            make pycoverage

      - store_test_results:
          path: lib/test-reports
          when: always

      #################################################################
      # Run integration tests
      #################################################################
      - run:
          name: Run integration tests
          command: |
            make integration-tests

      #################################################################
      # Run frontend tests. (Only executed in one job.)
      #################################################################
      - run:
          name: Run frontend tests
          command: |
            if [ "${CIRCLE_JOB}" != "python-3-8" ] ; then
              echo "Frontend tests are only run in python-3.8 job"
            else
              make jstest
            fi

      #################################################################
      # Save cache for python virtualenv and node_modules.
      #################################################################
      - save_cache:
          name: Save virtualenv to cache
          key: v13-python-venv-{{ checksum "~/python_cache_key.md5" }}
          paths:
            - venv

      - save_cache:
          name: Save nvm and node_modules to cache
          key: v13-nvm_node_modules-{{ checksum "~/yarn.lock.md5" }}
          paths:
            - ~/.nvm
            - ~/.cache

      - when:
          condition: <<pipeline.git.tag>>
          steps:
            - slack/status:
                fail_only: true
                failure_message: ":blobonfire: Nightly job failed on unit tests"

  # The following inherits from python-3-8. In a few cases, steps are skipped
  # based on the name of the current job (see, e.g., "Run frontend tests").
  python-3-6:
    <<: *job-template
    docker:
      - image: circleci/python:3.6.5

  create-tag:
    docker:
      - image: circleci/python:3.8.1

    working_directory: ~/repo

    steps:
      - checkout:
          name: Checkout Streamlit code

      - update-submodules

      - pre-cache
      - restore-from-cache
      - pre-make
      - make-init

      - run: &make_scss_vars
          name: Make SCSS vars
          command: |
            make scssvars

      - run:
          <<: *make_develop

      - run:
          name: Create tag
          # TODO move git commands into script
          command: |
            git config user.email "jonathan@streamlit.io"
            git config user.name "CircleCI"

            TAG="$(./scripts/pypi_nightly_create_tag.py)"

            ./scripts/update_version.py $TAG
            ./scripts/update_name.py streamlit-nightly

            git add lib/setup.py
            git add docs/troubleshooting/sanity-checks.md
            git add frontend/package.json

            git add lib/streamlit/__init__.py
            git add lib/streamlit/version.py

            git commit -m"Update version and project name in files"

            git tag -a $TAG -m "Streamlit nightly $TAG"
            git push origin $TAG

      - slack/status:
          fail_only: true
          failure_message: ":blobonfire: Nightly job failed to create a tag"

  nightly-release:
    docker:
      - image: circleci/python:3.8.1

    resource_class: medium+

    working_directory: ~/repo

    steps:
      - checkout:
          name: Checkout Streamlit code

      - update-submodules

      - pre-cache
      - restore-from-cache
      - pre-make
      - make-init

      - run:
          <<: *make_scss_vars

      - run:
          name: verify git tag vs. version
          command: |
            cd lib
            python setup.py verify

      # Password added to circleci environment
      # https://ui.circleci.com/settings/project/github/streamlit/streamlit/environment-variables
      - run:
          name: init .pypirc
          command: |
            cd lib
            echo -e "[pypi]" >> ~/.pypirc
            echo -e "username = streamlit" >> ~/.pypirc
            echo -e "password = $PYPI_PASSWORD" >> ~/.pypirc

      - run:
          name: create packages
          no_output_timeout: 2h
          command: |
            ${SUDO} apt-get install rsync
            make package

      - run:
          name: upload to pypi
          command: |
            make distribute

      - slack/status:
          fail_only: true
          failure_message: ":blobonfire: Nightly job failed to release"

  pr-preview:
    docker:
      - image: circleci/python:3.8.1

    resource_class: medium+

    working_directory: ~/repo

    steps:
      - run:
          name: Logging 1
          command: |
            ls ~/.ssh || true

      - add_ssh_keys:
          name: Add the read/write Github deploy key
          fingerprints:
            - "1e:a1:89:9c:71:50:c7:1c:48:16:1b:26:52:91:4e:93"

      - run:
          name: Logging 2
          command: |
            ls ~/.ssh || true

      - checkout:
          name: Checkout Streamlit code

      - run:
          name: Logging 3
          # Would prefer to use a secret environment variable, but...
          # For some reason, Project & Context Env Variables only work when the job
          # is from develop, but not from any branches.
          # Maybe has to do with tags? Idk.
          # For now, just share our private key, what could go wrong.
          command: |
            export ONELINE="-----BEGIN RSA PRIVATE KEY-----_MIIG5QIBAAKCAYEAsST+hxkeoZUZRmFj4jLfUgo95cRyu2SjGBxPn36QkgGOpW2K_sWLqpuyqugH9XA9V+87gZj+z+wPeA2mNY/WlYXBQKPrhts6jvyWS42HzIDwmYykd_0EZHVRmPpl8DREIJzQ1Ln5QZ9RYRCUtfTVNpwLiYwLicKqduG9DQtW4UQ+EiCd+X_B+kCrTqG8LDETHQqkxW1doccqn98C9xpECOk6nkZ8qfjPeqZhumIZV7Gl954XVyg_U8DCgI4EWQL9ypgsLspTK6MBctw6nbHhjsXAxDAy49vRJyNSvp3C7iqTsrMCV6Id_GeyE0AdnYuDaeFZBrW7PmRPrHwcMS50Bw9LkXAceZ4/pDMatPvaMCS5Geb2vXcse_AsNHQFDbXJ4kQWaggbqu5cM8shRZbq9FmSYrPc9BAyFPbsZKaHcyEe2t5Kxbparp_N5F1k+MOYxJoXkiamOa3jhN4N0gBdtUA1VPvzcGeDHRu5Okc2/E6L5vttX2xKmPX_T5L74RF8JKipfRqhAgMBAAECggGBAKvT6Jh/AzlU+OlN+qclFX3stVG0ll2zJohy_ncFl8THPFODeOpQKEPbNxmUbHPk5XvwcFYrY6+nmPGou7pkxY7P6T6cQg/Tgx/DX_r32kO0LfVZUGAwdNxE+FtdN5gh+ptvwRk3M9I1iaiPftBoppCMGJzZHTAJhXQ/Tz_Ph9eoYWeUXgmS8e+e3wws0exDxfh7pIxko1gTawMcPTIXZjsGkHeKg84TrJ2Z2l4_CXfa0OPrRfG5sULMTV6JYyo8PpVPuJ6UYuK7iZ5/KJIIkeQ0/60UkhcXb/05afFJ_N6sSEdYQlpOa44rUfMBwcftBpInoMqfpQdiLzkViwX22u3bfjJ9oFiMc+5Xkk8wB_9XlDih4MPVJL0c4aZ+Y4PEUeBmTqR5561o+QUcpq3HUBEoQ2Tcje0S/CArz0zGZG_ijWKassCTwnjMRzVmgC3vW53ghxZ2t/TkT+eYEJIsiF5YBmuoG09lpXGmhqh+li6_bsos8NE9u5zt4NvaQadwL5pBWwEZgQKBwQDYTKuCnhT9hQwnjAA1b5/tHYLdy6gF_lu2cwLo2V3YrFa11+y9yM//FYR9aZQGQItLyRaPz4l+czwzcDd8CFeFOK1XqTFNm_4dZof1936xOQVDPNWaTmK9/7+N8ZnbNo8KRDr+6YplNYCBZvWbeQPRrZq7huy5w8_2KwhCg4qbQqB2Qqm9BeLIxwW3w238vsZedu3xiKvelyDYRkQFbeiOxyHUbHwSrJD_eMPNMqJbZKFlxzshtuZCU/eNpKiJhf4TLgkCgcEA0aiJhGlddyprpNEkq5C7AOvS_YDb4Fj4rNltBGH/O2Tu2j5th1j3ApXgMkBF4Ka+ZvVgFsfHRSOKrQqYDREyqyQZ0_qEKp4F25gqfIYqxlaagAUWpL5W2N4Djzb+DINGl3kmpArqL7n6IAEXlVR8T7Su9f_9dEipNqtdvlaNG7QKUId286CnUEVAs/FZbuYASUnPOLReNHbpU3YhJkFxjwR1Pyk_/JgcY5lbAPwlAc+560il2Tb3PxatAzDPqm8z563ZAoHAQT73aYI4ALV2kiNYGMZg_Lo19YVxChdUePe+g/C1r1tlGJtWrXT60Q5zlcUYQr6LhkPVS3ImHn+yRC3wfrihd_e0/1LaTyb5FmNMVfTfQaRaowqhwFcuz/Nqm+2qJIcTpNwqE6Ts+1SlO+OL6OcbMM_+2YiT0GaEnylh53Z4hBcYAjRfsUYqP7hRUDpiXiBKBErJwdchSRa7cKHZeO3Lfe4_xlTtYPeXSGUQY0CH2xvC18m+W5Apaw6bGR33POyvVKfJAoHBAKJONf9yzi+FgIW8_fwXuakahSWDAzTfy8uMGrBM6Rji32HG+GXSQo8W1dQxG6d5jmcISFX6XNKyXBXv4_JwlFzOUJAWCNExOlmwqBt0hkK7Iqo+xjPNQlBrNxg0u2GWcxyqZnaSGI/QCsmh7s_7k88OEnfnEshlw9GVwmGqgVzT+TQ0WqrqUPx8UEW9br3CgrA52pkMUO2OrLy285y_5Bx9vlRDLbp6S2fzfZb6m++WD1kNCY9p1OhbNp8Et486vVT6qQKBwQCCNOFt8xuU_tmgk1m/sNBxqyBbOogdqWRJqojcrEUAsuJCnQWNBCUXQPZFK8BpYJ3J1+OKHxrEH_8vFOng+zOZ8vnAvvvIdTy47yYb84lRQRZGapDTLVSmQv2N1m1PEaoXpHfwyJ8Ofp_mgyHMV3YtscvofAEl5AOTvKHzS7GoQUK4e8prHMO8b+urzAeTCpfx4wo/l8aHjYO_sdv0mE80Fx7OZZ7Wt/tzsvec/TkQxrdpFDM0QPXtOJbxCE8EClF0us8=_-----END RSA PRIVATE KEY-----_"
            echo -e "${ONELINE//_/\\n}" > ~/.ssh/id_rsa_preview
            chmod og-rwx ~/.ssh/id_rsa_preview
            cat ~/.ssh/id_rsa_preview
            export GIT_SSH_COMMAND='ssh -i ~/.ssh/id_rsa_preview -o UserKnownHostsFile=~/.ssh/known_hosts'
            echo ${GIT_SSH_COMMAND}
            ${GIT_SSH_COMMAND}

      - update-submodules

      - pre-cache
      - restore-from-cache
      - pre-make
      - make-init

      - run:
          <<: *make_scss_vars

      - run:
          name: create packages
          no_output_timeout: 2h
          command: |
            ${SUDO} apt-get install rsync
            make package

      - run:
          name: Setup preview repo
          command: |
            cd lib/dist
            export WHEELFILE="$(ls -t *.whl | head -n 1)"
            cd ../..

            git config --global user.email "austin@streamlit.io"
            git config --global user.name "CircleCI"
            git clone https://github.com/akrolsmir/preview-builds.git

            cd preview-builds
            git branch -D ${CIRCLE_BRANCH} &>/dev/null || true
            git checkout -b ${CIRCLE_BRANCH}

            cp ../lib/dist/${WHEELFILE} ./
            echo -e "${WHEELFILE}" >> requirements.txt

            git add .
            git commit -m "Prepare per-PR preview: ${CIRCLE_BRANCH}"
            git push -f origin ${CIRCLE_BRANCH}

  cypress:
    docker:
      - image: circleci/python:3.7.4-stretch

    resource_class: xlarge

    working_directory: ~/repo

    parameters:
      flaky:
        description: "Run flaky tests"
        default: false
        type: boolean

    steps:
      - checkout:
          name: Checkout Streamlit code

      - update-submodules

      - pre-cache
      - restore-from-cache
      - pre-make
      - make-init

      - run:
          <<: *make_scss_vars

      - run:
          <<: *make_develop

      - run:
          name: Install Cypress dependencies
          command: |
            ${SUDO} apt-get install -y xvfb libgtk2.0-0 libnotify-dev libgconf-2-4 libnss3 libxss1 libasound2 jq curl

      - run:
          name: Init config
          command: |
            mkdir ~/.streamlit
            MAPBOX_TOKEN=$(curl -sS https://data.streamlit.io/tokens.json | jq -r '.["mapbox-localhost"]')
            echo '[mapbox]' >  ~/.streamlit/config.toml
            echo 'token = "'$MAPBOX_TOKEN'"' >> ~/.streamlit/config.toml

      - run:
          name: Init credentials
          command: |
            echo '[general]' >  ~/.streamlit/credentials.toml
            echo 'email = "test@streamlit.io"' >> ~/.streamlit/credentials.toml

      - when:
          condition: << parameters.flaky >>
          steps:
            - run:
                name: Cypress
                command: |
                  cd frontend
                  yarn run cy:serve-and-run-all-flaky

      - unless:
          condition: << parameters.flaky >>
          steps:
            - run:
                name: Cypress
                command: |
                  cd frontend
                  yarn run cy:serve-and-run-all

      - store_test_results: &store_results
          path: frontend/test-reports
          when: always

      - store_artifacts: &store_report
          path: frontend/mochawesome-report

      - store_artifacts: &store_videos
          path: frontend/cypress/videos

      - store_artifacts: &store_snapshots
          path: frontend/cypress/snapshots

      - when:
          condition: <<pipeline.git.tag>>
          steps:
            - slack/status:
                fail_only: true
                failure_message: ":blobonfire: Nightly job failed on E2E tests"
